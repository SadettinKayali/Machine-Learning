{"cells":[{"cell_type":"markdown","id":"c1f4b4c7","metadata":{},"source":["Supervised learning is a type of machine learning in which a computer algorithm is trained using input data together with its expected output. The algorithm learns to map the input data to the output, so that it can make predictions about new data. Supervised learning is often used for tasks such as classification and regression."]},{"cell_type":"markdown","id":"96d7fd29","metadata":{},"source":["Machine learning is traditionally divided into two main categories: supervised and unsupervised learning. We will start with supervised learning and one of its techniques: regression."]},{"cell_type":"markdown","id":"e9efc7af","metadata":{},"source":["First, what do we mean by supervised machine learning? It is an approach where a computer algorithm is trained using input data and the expected output. In other words, we know the answer and have nicely labeled it as well. This is why we can also call the expected output “labels” or “ground truth”. In unsupervised learning, on the other hand, the training data is not labeled by humans in advance and the machine has to come up with meaningful answers."]},{"cell_type":"markdown","id":"b2d44963","metadata":{},"source":["Regression is a type of supervised learning that uses an algorithm to understand the relationship between a dependent variable, that is the input, and an independent variable, which is the output. Regression models are helpful for predicting numerical values based on different features’ values. For example, temperature forecast based on wind, humidity and pressure, or price estimations of a car based on its model year, brand, and transmission type. In regression, we want to build a relationship between each feature and the output so that we can predict for example, the price of the house when we know the features but not the price. If this relationship is linear, this algorithm is called linear regression."]},{"cell_type":"markdown","id":"49e81506","metadata":{},"source":["Linear regression is perhaps the most well-known and well-understood algorithm in statistics and machine learning. \n","A simple linear regression model tries to explain the relationship between the two variables using a best fitting straight line. We call this a regression line. "]},{"cell_type":"markdown","id":"b34e96e9","metadata":{},"source":["The independent variable X is used to predict the value of the dependent variable which is represented as Y. In our example, X is rainfall measured in millimeters and Y is the number of umbrellas sold.\n","We want to find out the equation of the line: Y = wX + b.\n","Here, w is the slope of the gradient of the line. It indicates how much the variable X impacts Y, which is why we call it the “weight”. And b is the value of Y when there is no X or the X is zero, this is called the “bias”."]},{"cell_type":"markdown","id":"a90822fb","metadata":{},"source":["There are many possible strategies to calculate the regression line; the most popular one is the least squares. We start by drawing a line to represent this relationship. Then we measure the distances between the line and each datapoint, the residuals. We sum up the residuals, then adjust the weight and the bias to minimize total residual to find the best line. This was simple linear regression because there was only one feature therefore, only one weight. When we have multiple features, it’s called multiple linear regression. Let’s work on multiple linear regression with a new example."]},{"cell_type":"markdown","id":"264c13d0","metadata":{},"source":["We want to find the equation of this line: Y = w1X1 + w2X2 + …and so on + b.\n","\n","Here, X are the features, the w are the weights associated to each feature, and b is the bias. Now, let’s say we have trained a model and weights and bias are learned. But how do we know if the model predictions are correct and not some random numbers thrown by the model? We need to evaluate the performance of this regression model and for this purpose, we use performance evaluation metrics.\n","\n","One of the most commonly used evaluation metrics is just taking the difference between predicted and actual value of some test points. But this difference can be positive or negative and if we compute the total difference, the positive and negative will cancel out each other. To solve this problem, we square all the differences. Now all the differences are positive but squared. Then, we take the mean of these values. This value is called the Mean Squared Error, MSE. To better understand how big the error is, we take the square root of it and get the Root Mean Squared Error RMSE. This RMSE is in the same unit as the predictions. "]},{"cell_type":"markdown","id":"89612877","metadata":{},"source":["The first step is reading the data. To do that, we need to import Python’s handy data science library, Pandas."]},{"cell_type":"code","execution_count":20,"id":"e4ad459d","metadata":{"executionInfo":{"elapsed":615,"status":"ok","timestamp":1652814905336,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"e4ad459d"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"markdown","id":"2498fa3f","metadata":{},"source":["After importing the pandas library we can easily load our train and test datasets using read_csv. We will use the train dataset to help our regression model to learn some important patterns in the data. "]},{"cell_type":"code","execution_count":21,"id":"bedf4252","metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1652814995097,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"bedf4252"},"outputs":[],"source":["train = pd.read_csv(\"train.csv\")\n","test = pd.read_csv(\"test.csv\")"]},{"cell_type":"markdown","id":"1ifEFyw1ckNV","metadata":{"id":"1ifEFyw1ckNV"},"source":["# New Section"]},{"cell_type":"markdown","id":"600e2b84","metadata":{},"source":["Then we’ll use the test dataset to check how well the model learned the patterns or how well it predicts. Let’s start with this simple operation. Let’s observe features in our train dataset. We can see that some of the features we have include the house’s general quality, the year it was built, the size of the garage, and so on."]},{"cell_type":"code","execution_count":22,"id":"23f35b61","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1652815631361,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"23f35b61","outputId":"049920b2-300b-4c23-d6d2-017a58884fb4"},"outputs":[{"data":{"text/plain":["Index(['OverallQual', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', '1stFlrSF',\n","       'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea',\n","       'SalePrice', 'ExterQual_TA', 'Foundation_PConc', 'KitchenQual_TA'],\n","      dtype='object')"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["train.columns"]},{"cell_type":"markdown","id":"78061987","metadata":{},"source":["Now that we have our datasets loaded, we can import linear regression models from the most important machine learning library of Python; sklearn. It is an open-source library for machine learning. There are many models constructed in this library, we just need to import the one that we will use."]},{"cell_type":"code","execution_count":23,"id":"f3bb245b","metadata":{"executionInfo":{"elapsed":576,"status":"ok","timestamp":1652815635007,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"f3bb245b"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression"]},{"cell_type":"markdown","id":"87347012","metadata":{},"source":["After importing linear regression model, we can assign it to the “model” variable to use it easily. In this example, we’re trying to predict the house prices. The column we want to predict also is called “ground truth”, “target” or “labels” and other columns are called “features” or “attributes”. For the model to predict the house prices, first, we need to define which column has the house prices, or the ground truth. "]},{"cell_type":"code","execution_count":24,"id":"4a2cd3f1","metadata":{"executionInfo":{"elapsed":606,"status":"ok","timestamp":1652815641907,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"4a2cd3f1"},"outputs":[],"source":["model = LinearRegression()"]},{"cell_type":"markdown","id":"5c6ed96a","metadata":{},"source":["Then we remove it from the features of the data using the drop function and assign it as ‘labels’ using the loc function. Inside the drop function, we write the column name followed by the argument axis which we set to 1. This indicates that the specified column needs to be deleted. Basically, we want to predict y with the help of x. And generally, we assign target to the y variable, features to the X variable. "]},{"cell_type":"code","execution_count":25,"id":"869e4782","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1652815644608,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"869e4782"},"outputs":[],"source":["X_train = train.drop('SalePrice', axis=1)\n","y_train = train.loc[:,'SalePrice']"]},{"cell_type":"markdown","id":"35814537","metadata":{},"source":["Then we can fit our model, which means teaching the hidden patterns in the training dataset into it. "]},{"cell_type":"code","execution_count":26,"id":"7545b918","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1652815649497,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"7545b918","outputId":"40e56fdd-11ad-40f4-95e7-3da58d69bb39"},"outputs":[{"data":{"text/plain":["LinearRegression()"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(X_train,y_train)"]},{"cell_type":"markdown","id":"d5e6eeb9","metadata":{},"source":[" After the fitting process, our model is almost ready to make predictions. But before that, we also need to divide our test dataset into “target” and “features”."]},{"cell_type":"code","execution_count":27,"id":"6d34fc45","metadata":{"executionInfo":{"elapsed":247,"status":"ok","timestamp":1652815653112,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"6d34fc45"},"outputs":[],"source":["X_test = test.drop('SalePrice', axis=1)\n","y_test = test.loc[:,'SalePrice']"]},{"cell_type":"markdown","id":"ec6d75d8","metadata":{},"source":["Here the target dataset contains the actual values which our model will compare its predictions. Now, we are completely ready to make predictions using the features of the test dataset. Let’s observe our predictions and actual test values. For that, we can simply put them into the same data frame and observe some of the rows using head and tail functions. We see that the actual values and the predictions by our model are more or less close. Of course, as in every machine learning model, there are some inaccuracies, but we will gradually reduce those and increase the accuracy of the model. Don’t worry, this is just your first model! Of course, comparing some data points with your eyes won’t tell you how well your model predicts. This is exactly where we use evaluation metrics! "]},{"cell_type":"code","execution_count":28,"id":"f2f715de","metadata":{"executionInfo":{"elapsed":230,"status":"ok","timestamp":1652815673350,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"f2f715de"},"outputs":[],"source":["predictions = model.predict(X_test)"]},{"cell_type":"markdown","id":"7c16cc0d","metadata":{},"source":[" Let’s import mean squared error from the sklearn library. We also need to import square root from the NumPy library, because we want to observe our root mean squared error as it’s in the same unit with our data. After importing, we can use these functions to average the calculated error."]},{"cell_type":"code","execution_count":29,"id":"a70d0388","metadata":{"executionInfo":{"elapsed":315,"status":"ok","timestamp":1652815807899,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"a70d0388"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","from numpy import sqrt"]},{"cell_type":"markdown","id":"f88a8e5a","metadata":{},"source":["Our RMSE is approximately 33 000! If we consider our average price is 185 000, and maximum price as big as 500 000, then 33 000 may be considered normal for your first model. Keep going! Also, we can check which features have the most impact on our predictions. "]},{"cell_type":"code","execution_count":30,"id":"636248b2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1652815809991,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"636248b2","outputId":"0fda5928-aa43-45f5-f5d5-14487030f4bf"},"outputs":[{"data":{"text/plain":["33186.384172367674"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["rmse = sqrt(mean_squared_error(y_test, predictions))\n","rmse"]},{"cell_type":"markdown","id":"7fa7b7d3","metadata":{},"source":["Basically, we can check for correlations on our train dataset. But since we need correlations between target and features, we can simply take the “SalePrice” column from this data frame. From the data frame, we can’t decide which ones have the most impact. Let’s sort and see the top 10 using sort_values, "]},{"cell_type":"code","execution_count":31,"id":"916087ab","metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1652815813946,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"916087ab"},"outputs":[],"source":["comparison = pd.DataFrame({\"Actual Values\": y_test,\"Predictions\": predictions})"]},{"cell_type":"markdown","id":"6743bfe4","metadata":{},"source":[" then head functions. Don’t forget that we need to set ascending as false because we want to see 10 highest values!"]},{"cell_type":"code","execution_count":32,"id":"b969e300","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1652815816999,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"b969e300","outputId":"3ed249aa-6a8c-4419-e23f-0d284ae122ef"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Actual Values</th>\n","      <th>Predictions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>118500</td>\n","      <td>83380.944694</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>154900</td>\n","      <td>105974.149765</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>133000</td>\n","      <td>139238.138343</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>115000</td>\n","      <td>104982.049557</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>154500</td>\n","      <td>140473.360146</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Actual Values    Predictions\n","0         118500   83380.944694\n","1         154900  105974.149765\n","2         133000  139238.138343\n","3         115000  104982.049557\n","4         154500  140473.360146"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["comparison.head()"]},{"cell_type":"code","execution_count":33,"id":"c3641180","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1652815821107,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"c3641180","outputId":"1fe388df-2468-49d0-dbda-1d03dc665b6c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Actual Values</th>\n","      <th>Predictions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>324</th>\n","      <td>132250</td>\n","      <td>102816.796295</td>\n","    </tr>\n","    <tr>\n","      <th>325</th>\n","      <td>123000</td>\n","      <td>121698.649065</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>316600</td>\n","      <td>271745.844407</td>\n","    </tr>\n","    <tr>\n","      <th>327</th>\n","      <td>142000</td>\n","      <td>131258.275591</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>250000</td>\n","      <td>263005.372419</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     Actual Values    Predictions\n","324         132250  102816.796295\n","325         123000  121698.649065\n","326         316600  271745.844407\n","327         142000  131258.275591\n","328         250000  263005.372419"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["comparison.tail()"]},{"cell_type":"markdown","id":"d1b08b94","metadata":{},"source":[]},{"cell_type":"code","execution_count":34,"id":"4b254811","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316,"status":"ok","timestamp":1652815826343,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"4b254811","outputId":"ea5c9491-7280-4cd8-bcc7-73257a018a7f"},"outputs":[{"data":{"text/plain":["SalePrice           1.000000\n","OverallQual         0.792263\n","GrLivArea           0.712054\n","GarageCars          0.658355\n","GarageArea          0.621354\n","1stFlrSF            0.621057\n","TotalBsmtSF         0.612205\n","FullBath            0.597505\n","TotRmsAbvGrd        0.573845\n","Foundation_PConc    0.517222\n","Name: SalePrice, dtype: float64"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["train.corr()[\"SalePrice\"].sort_values(ascending=False).head(10)"]},{"cell_type":"code","execution_count":35,"id":"82481e20","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":552},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1652815835972,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"82481e20","outputId":"db15ec73-b2a9-46ac-f79e-a6ff4aa062b4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>OverallQual</th>\n","      <th>YearBuilt</th>\n","      <th>YearRemodAdd</th>\n","      <th>TotalBsmtSF</th>\n","      <th>1stFlrSF</th>\n","      <th>GrLivArea</th>\n","      <th>FullBath</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>GarageCars</th>\n","      <th>GarageArea</th>\n","      <th>SalePrice</th>\n","      <th>ExterQual_TA</th>\n","      <th>Foundation_PConc</th>\n","      <th>KitchenQual_TA</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>OverallQual</th>\n","      <td>1.000000</td>\n","      <td>0.572367</td>\n","      <td>0.550407</td>\n","      <td>0.557685</td>\n","      <td>0.539527</td>\n","      <td>0.628890</td>\n","      <td>0.598265</td>\n","      <td>0.482744</td>\n","      <td>0.627897</td>\n","      <td>0.579378</td>\n","      <td>0.792263</td>\n","      <td>-0.692146</td>\n","      <td>0.593079</td>\n","      <td>-0.579892</td>\n","    </tr>\n","    <tr>\n","      <th>YearBuilt</th>\n","      <td>0.572367</td>\n","      <td>1.000000</td>\n","      <td>0.615451</td>\n","      <td>0.418706</td>\n","      <td>0.315715</td>\n","      <td>0.205311</td>\n","      <td>0.496001</td>\n","      <td>0.122193</td>\n","      <td>0.530869</td>\n","      <td>0.466243</td>\n","      <td>0.503317</td>\n","      <td>-0.608600</td>\n","      <td>0.675289</td>\n","      <td>-0.478635</td>\n","    </tr>\n","    <tr>\n","      <th>YearRemodAdd</th>\n","      <td>0.550407</td>\n","      <td>0.615451</td>\n","      <td>1.000000</td>\n","      <td>0.305751</td>\n","      <td>0.299912</td>\n","      <td>0.300983</td>\n","      <td>0.500358</td>\n","      <td>0.189233</td>\n","      <td>0.507051</td>\n","      <td>0.459938</td>\n","      <td>0.504414</td>\n","      <td>-0.586210</td>\n","      <td>0.608433</td>\n","      <td>-0.621112</td>\n","    </tr>\n","    <tr>\n","      <th>TotalBsmtSF</th>\n","      <td>0.557685</td>\n","      <td>0.418706</td>\n","      <td>0.305751</td>\n","      <td>1.000000</td>\n","      <td>0.912271</td>\n","      <td>0.517430</td>\n","      <td>0.370448</td>\n","      <td>0.337671</td>\n","      <td>0.476327</td>\n","      <td>0.539858</td>\n","      <td>0.612205</td>\n","      <td>-0.414837</td>\n","      <td>0.330111</td>\n","      <td>-0.353424</td>\n","    </tr>\n","    <tr>\n","      <th>1stFlrSF</th>\n","      <td>0.539527</td>\n","      <td>0.315715</td>\n","      <td>0.299912</td>\n","      <td>0.912271</td>\n","      <td>1.000000</td>\n","      <td>0.589766</td>\n","      <td>0.392271</td>\n","      <td>0.416777</td>\n","      <td>0.472616</td>\n","      <td>0.531808</td>\n","      <td>0.621057</td>\n","      <td>-0.355415</td>\n","      <td>0.262008</td>\n","      <td>-0.315156</td>\n","    </tr>\n","    <tr>\n","      <th>GrLivArea</th>\n","      <td>0.628890</td>\n","      <td>0.205311</td>\n","      <td>0.300983</td>\n","      <td>0.517430</td>\n","      <td>0.589766</td>\n","      <td>1.000000</td>\n","      <td>0.624707</td>\n","      <td>0.826999</td>\n","      <td>0.492914</td>\n","      <td>0.499800</td>\n","      <td>0.712054</td>\n","      <td>-0.427637</td>\n","      <td>0.340340</td>\n","      <td>-0.384288</td>\n","    </tr>\n","    <tr>\n","      <th>FullBath</th>\n","      <td>0.598265</td>\n","      <td>0.496001</td>\n","      <td>0.500358</td>\n","      <td>0.370448</td>\n","      <td>0.392271</td>\n","      <td>0.624707</td>\n","      <td>1.000000</td>\n","      <td>0.550967</td>\n","      <td>0.528268</td>\n","      <td>0.465081</td>\n","      <td>0.597505</td>\n","      <td>-0.516471</td>\n","      <td>0.519781</td>\n","      <td>-0.474227</td>\n","    </tr>\n","    <tr>\n","      <th>TotRmsAbvGrd</th>\n","      <td>0.482744</td>\n","      <td>0.122193</td>\n","      <td>0.189233</td>\n","      <td>0.337671</td>\n","      <td>0.416777</td>\n","      <td>0.826999</td>\n","      <td>0.550967</td>\n","      <td>1.000000</td>\n","      <td>0.426842</td>\n","      <td>0.389448</td>\n","      <td>0.573845</td>\n","      <td>-0.307535</td>\n","      <td>0.255900</td>\n","      <td>-0.251362</td>\n","    </tr>\n","    <tr>\n","      <th>GarageCars</th>\n","      <td>0.627897</td>\n","      <td>0.530869</td>\n","      <td>0.507051</td>\n","      <td>0.476327</td>\n","      <td>0.472616</td>\n","      <td>0.492914</td>\n","      <td>0.528268</td>\n","      <td>0.426842</td>\n","      <td>1.000000</td>\n","      <td>0.845512</td>\n","      <td>0.658355</td>\n","      <td>-0.543945</td>\n","      <td>0.517289</td>\n","      <td>-0.465095</td>\n","    </tr>\n","    <tr>\n","      <th>GarageArea</th>\n","      <td>0.579378</td>\n","      <td>0.466243</td>\n","      <td>0.459938</td>\n","      <td>0.539858</td>\n","      <td>0.531808</td>\n","      <td>0.499800</td>\n","      <td>0.465081</td>\n","      <td>0.389448</td>\n","      <td>0.845512</td>\n","      <td>1.000000</td>\n","      <td>0.621354</td>\n","      <td>-0.511492</td>\n","      <td>0.451725</td>\n","      <td>-0.455758</td>\n","    </tr>\n","    <tr>\n","      <th>SalePrice</th>\n","      <td>0.792263</td>\n","      <td>0.503317</td>\n","      <td>0.504414</td>\n","      <td>0.612205</td>\n","      <td>0.621057</td>\n","      <td>0.712054</td>\n","      <td>0.597505</td>\n","      <td>0.573845</td>\n","      <td>0.658355</td>\n","      <td>0.621354</td>\n","      <td>1.000000</td>\n","      <td>-0.598202</td>\n","      <td>0.517222</td>\n","      <td>-0.527176</td>\n","    </tr>\n","    <tr>\n","      <th>ExterQual_TA</th>\n","      <td>-0.692146</td>\n","      <td>-0.608600</td>\n","      <td>-0.586210</td>\n","      <td>-0.414837</td>\n","      <td>-0.355415</td>\n","      <td>-0.427637</td>\n","      <td>-0.516471</td>\n","      <td>-0.307535</td>\n","      <td>-0.543945</td>\n","      <td>-0.511492</td>\n","      <td>-0.598202</td>\n","      <td>1.000000</td>\n","      <td>-0.673381</td>\n","      <td>0.683627</td>\n","    </tr>\n","    <tr>\n","      <th>Foundation_PConc</th>\n","      <td>0.593079</td>\n","      <td>0.675289</td>\n","      <td>0.608433</td>\n","      <td>0.330111</td>\n","      <td>0.262008</td>\n","      <td>0.340340</td>\n","      <td>0.519781</td>\n","      <td>0.255900</td>\n","      <td>0.517289</td>\n","      <td>0.451725</td>\n","      <td>0.517222</td>\n","      <td>-0.673381</td>\n","      <td>1.000000</td>\n","      <td>-0.600103</td>\n","    </tr>\n","    <tr>\n","      <th>KitchenQual_TA</th>\n","      <td>-0.579892</td>\n","      <td>-0.478635</td>\n","      <td>-0.621112</td>\n","      <td>-0.353424</td>\n","      <td>-0.315156</td>\n","      <td>-0.384288</td>\n","      <td>-0.474227</td>\n","      <td>-0.251362</td>\n","      <td>-0.465095</td>\n","      <td>-0.455758</td>\n","      <td>-0.527176</td>\n","      <td>0.683627</td>\n","      <td>-0.600103</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  OverallQual  YearBuilt  YearRemodAdd  TotalBsmtSF  1stFlrSF  \\\n","OverallQual          1.000000   0.572367      0.550407     0.557685  0.539527   \n","YearBuilt            0.572367   1.000000      0.615451     0.418706  0.315715   \n","YearRemodAdd         0.550407   0.615451      1.000000     0.305751  0.299912   \n","TotalBsmtSF          0.557685   0.418706      0.305751     1.000000  0.912271   \n","1stFlrSF             0.539527   0.315715      0.299912     0.912271  1.000000   \n","GrLivArea            0.628890   0.205311      0.300983     0.517430  0.589766   \n","FullBath             0.598265   0.496001      0.500358     0.370448  0.392271   \n","TotRmsAbvGrd         0.482744   0.122193      0.189233     0.337671  0.416777   \n","GarageCars           0.627897   0.530869      0.507051     0.476327  0.472616   \n","GarageArea           0.579378   0.466243      0.459938     0.539858  0.531808   \n","SalePrice            0.792263   0.503317      0.504414     0.612205  0.621057   \n","ExterQual_TA        -0.692146  -0.608600     -0.586210    -0.414837 -0.355415   \n","Foundation_PConc     0.593079   0.675289      0.608433     0.330111  0.262008   \n","KitchenQual_TA      -0.579892  -0.478635     -0.621112    -0.353424 -0.315156   \n","\n","                  GrLivArea  FullBath  TotRmsAbvGrd  GarageCars  GarageArea  \\\n","OverallQual        0.628890  0.598265      0.482744    0.627897    0.579378   \n","YearBuilt          0.205311  0.496001      0.122193    0.530869    0.466243   \n","YearRemodAdd       0.300983  0.500358      0.189233    0.507051    0.459938   \n","TotalBsmtSF        0.517430  0.370448      0.337671    0.476327    0.539858   \n","1stFlrSF           0.589766  0.392271      0.416777    0.472616    0.531808   \n","GrLivArea          1.000000  0.624707      0.826999    0.492914    0.499800   \n","FullBath           0.624707  1.000000      0.550967    0.528268    0.465081   \n","TotRmsAbvGrd       0.826999  0.550967      1.000000    0.426842    0.389448   \n","GarageCars         0.492914  0.528268      0.426842    1.000000    0.845512   \n","GarageArea         0.499800  0.465081      0.389448    0.845512    1.000000   \n","SalePrice          0.712054  0.597505      0.573845    0.658355    0.621354   \n","ExterQual_TA      -0.427637 -0.516471     -0.307535   -0.543945   -0.511492   \n","Foundation_PConc   0.340340  0.519781      0.255900    0.517289    0.451725   \n","KitchenQual_TA    -0.384288 -0.474227     -0.251362   -0.465095   -0.455758   \n","\n","                  SalePrice  ExterQual_TA  Foundation_PConc  KitchenQual_TA  \n","OverallQual        0.792263     -0.692146          0.593079       -0.579892  \n","YearBuilt          0.503317     -0.608600          0.675289       -0.478635  \n","YearRemodAdd       0.504414     -0.586210          0.608433       -0.621112  \n","TotalBsmtSF        0.612205     -0.414837          0.330111       -0.353424  \n","1stFlrSF           0.621057     -0.355415          0.262008       -0.315156  \n","GrLivArea          0.712054     -0.427637          0.340340       -0.384288  \n","FullBath           0.597505     -0.516471          0.519781       -0.474227  \n","TotRmsAbvGrd       0.573845     -0.307535          0.255900       -0.251362  \n","GarageCars         0.658355     -0.543945          0.517289       -0.465095  \n","GarageArea         0.621354     -0.511492          0.451725       -0.455758  \n","SalePrice          1.000000     -0.598202          0.517222       -0.527176  \n","ExterQual_TA      -0.598202      1.000000         -0.673381        0.683627  \n","Foundation_PConc   0.517222     -0.673381          1.000000       -0.600103  \n","KitchenQual_TA    -0.527176      0.683627         -0.600103        1.000000  "]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["correlations = train.corr()\n","correlations"]},{"cell_type":"code","execution_count":36,"id":"a296f2bf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1652815842417,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"a296f2bf","outputId":"9fe983d8-3c9b-48dd-ce8b-266fd0af4984"},"outputs":[{"data":{"text/plain":["OverallQual         0.792263\n","YearBuilt           0.503317\n","YearRemodAdd        0.504414\n","TotalBsmtSF         0.612205\n","1stFlrSF            0.621057\n","GrLivArea           0.712054\n","FullBath            0.597505\n","TotRmsAbvGrd        0.573845\n","GarageCars          0.658355\n","GarageArea          0.621354\n","SalePrice           1.000000\n","ExterQual_TA       -0.598202\n","Foundation_PConc    0.517222\n","KitchenQual_TA     -0.527176\n","Name: SalePrice, dtype: float64"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["saleprice_correlations = correlations[\"SalePrice\"]\n","saleprice_correlations"]},{"cell_type":"code","execution_count":37,"id":"26a6b621","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1652815850822,"user":{"displayName":"Elena Zheglova","userId":"00916814404629677974"},"user_tz":-120},"id":"26a6b621","outputId":"e3ee434f-3a1d-43ca-f0a9-72147a0e9d58"},"outputs":[{"data":{"text/plain":["SalePrice           1.000000\n","OverallQual         0.792263\n","GrLivArea           0.712054\n","GarageCars          0.658355\n","GarageArea          0.621354\n","1stFlrSF            0.621057\n","TotalBsmtSF         0.612205\n","FullBath            0.597505\n","TotRmsAbvGrd        0.573845\n","Foundation_PConc    0.517222\n","Name: SalePrice, dtype: float64"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["saleprice_correlations.sort_values(ascending=False).head(10)"]},{"cell_type":"markdown","id":"a0c6c8d0","metadata":{},"source":["Here, we can see the features that have the strongest relation to the target variable. Overall material and finish of the house, ground living area square feet, and garage size in car capacity are the top three features that have the strongest correlation with house sale price. This means they have the biggest impact on predicting it. You can also see that the first feature in this list is the sale price of the house, with a correlation of 1. That is normal, because the correlation of a variable with itself is 1. This is all for now. In this video we learned about supervised learning, regression, and linear regression. We trained a house price prediction model using a real-world dataset. The Colab notebook is available in the course materials. Feel free to play with this model by changing its parameters or features.\n","\n","Well, while this is a very useful model for some types of problems, for the most part the world is not linear. Think about a typical tennis player. In the beginning of her career, she was learning. Then, her performance was at its peak and there was no one like her. With time, she aged, and her performance dropped. We cannot model a linear regression to calculate the performance of a sportsperson because this is a non-linear problem, and the linear regression model works well for linear equations."]},{"cell_type":"markdown","id":"a193471b","metadata":{},"source":["In supervised learning, input data is used with its expected output. In unsupervised learning, on the other hand, the training data is not labeled by humans in advance, and the machine has to come up with meaningful answers. Reinforcement learning is a method where the desired input is rewarded and the undesired one is punished. Ensemble learning uses predictions from different models and combines them to get better results.\n","\n","The method .predict(X) is used to make a prediction about the given value X. The model.guess(X), model.result(X) and model.estimate(X) methods do not exist in the sklearn library.\n","\n","In sklearn, model objects have a method called .fit() that's used to train a model. The methods model.learn(X_train,y_train) and model.test(X_train,y_train) do not exist in the sklearn library.\n","\n","Sklearn, also known as Scikit-learn, is the most commonly used library for importing machine learning modules in Python. NumPy and Pandas libraries are mostly used in preprocessing data. Matplotlib is used for visualizing the data.\n","\n","MSE & RMSE are the most commonly used evaluation metrics in regression. For mean squared error (MSE), the difference between predicted and actual value of some test points is taken and its value is squared. Then, the mean of these values is taken. To better understand how big the error is, we take the square root of it and get the root mean squared error (RMSE).\n","\n","Mean squared error (MSE) takes the difference between predicted and actual values. But, this difference can be positive or negative and when we compute the total difference, the positive and negative values will cancel each other out. To prevent this, the difference is squared and the mean of these values is calculated.\n","\n","Correlation shows the statistical relationship between variables. Gradient, feature metrics and matrix terms have nothing to do with statistical relationships between variables.\n","\n","Two of these methods are relevant in linear regression. We use mean squared error to measure the difference between the predicted and actual values and to evaluate how well our regression model is performing. We use the least square method to minimize the least square errors of the model to identify the line of best fit.\n","\n","The formula of the regression line is y = wX +b where “w” is the weight and “b” is the bias.\n","\n","Linear Regression uses a best-fitting straight line, called a regression line, to explain the relationship between two variables. Multivariate regression tries to explain the relationship between variables and more than one outcome. Polynomial regression tries to explain the relationship between variables with a nth degree polynomial line. Logistic regression tries to predict the probability of an event occuring.\n","\n","egression models help  predict numerical values or quantities. For example, the temperature measured in Celsius or Fahrenheit, or car prices in Euro or US dollars. Regression models are not suitable for predicting categories or clusters of data.\n","\n","Supervised learning allows us to find patterns in labeled data. A computer algorithm is trained using input data that has been labeled for an expected output. The other machine learning approaches do not have labeled data.\n","\n","\n"]}],"metadata":{"colab":{"name":"Regression.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}
